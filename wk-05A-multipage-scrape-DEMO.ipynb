{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rg5ypHYQ2vB"
   },
   "source": [
    "# Multipage Tables Scrape Demo\n",
    "\n",
    "You're often going to encounter data and tables spread across hundreds if not thousands of pages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FAa4EkaQ2vH"
   },
   "source": [
    "We're going to scrape as a demo a table that runs across several pages on <a href=\"https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html\">this mock website</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTY4tDkVQ2vI"
   },
   "source": [
    "To capture your target information into a single CSV file will require the use of many of the foundational skills we've covered, including:\n",
    "\n",
    "- ```delays```\n",
    "- ```conditional logic```\n",
    "- ```while loops```\n",
    "- ```BeautifulSoup```\n",
    "\n",
    "\n",
    "And we'll explore a few new functional Python methods today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzHxjNFUQ2vI"
   },
   "source": [
    "## Scraping Strategies\n",
    "\n",
    "- How do we approach this scrape?\n",
    "- What pattern do we see?\n",
    "- How do we capture a table on a single page?\n",
    "- How do we capture a sequence of tables?\n",
    "- How we navigate from page 1 to the subsequent pages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9IgexKhQ2vJ"
   },
   "source": [
    "# Let's code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tZ7ZNO8YQ2vJ"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "#from bs4 import BeautifulSoup  ## web scraping\n",
    "import requests ## request html for a page(s)\n",
    "import pandas as pd ## pandas to work with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl2yMzxEQ2vK"
   },
   "source": [
    "## Single Table Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "L3eCtCpJQ2vK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## request url website\n",
    "\n",
    "url = \"https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html\"\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PShccOFp4Xg7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## page content type\n",
    "\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALWAYS RESPONSE.TEXT, FOR HTML\n",
    "\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq7Fxh77KLU8"
   },
   "source": [
    "## Since ```page.text``` returns a ```str```, we don't need to use ```BeautifulSoup```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gh83GGbyQ2vL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                 Animal  Weight(kg)    Type\n",
       " 0            Blue whale      136000  Marine\n",
       " 1         Bowhead whale      100000  Marine\n",
       " 2             Fin whale       70000  Marine\n",
       " 3  Southern right whale       45000  Marine\n",
       " 4        Humpback whale       30000  Marine]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use Pandas to read tables on page\n",
    "\n",
    "df_list =pd.read_html(response.text)\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MvtGiiY7Q2vL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Do we want the first table?\n",
    "# type(df)\n",
    "\n",
    "type(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SLICE IT\n",
    "\n",
    "type(df_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dXIYAPPqQ2vL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Weight(kg)</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue whale</td>\n",
       "      <td>136000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bowhead whale</td>\n",
       "      <td>100000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fin whale</td>\n",
       "      <td>70000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Southern right whale</td>\n",
       "      <td>45000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Humpback whale</td>\n",
       "      <td>30000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Animal  Weight(kg)    Type\n",
       "0            Blue whale      136000  Marine\n",
       "1         Bowhead whale      100000  Marine\n",
       "2             Fin whale       70000  Marine\n",
       "3  Southern right whale       45000  Marine\n",
       "4        Humpback whale       30000  Marine"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## store it into a copy called animals_df\n",
    "\n",
    "animals_df = df_list[0]\n",
    "animals_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gheKHsbiQ2vM"
   },
   "source": [
    "## But we want to scrape multiple pages\n",
    "2 ways to build a list of urls that we have to navigate to:\n",
    "\n",
    "1. Placeholders\n",
    "2. f-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "euCu3yvc6GsF"
   },
   "outputs": [],
   "source": [
    "## Never do this manually\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVz1WRdPQ2vM"
   },
   "source": [
    "### 1. Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hfuCNbRFQ2vM"
   },
   "outputs": [],
   "source": [
    "## How is it different?\n",
    "\n",
    "url = \"https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page{}.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROt6YrlcQ2vM"
   },
   "source": [
    "## Placeholders\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/sandeepmj/scrape-example-page/master/images/placeholder1.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZXNStCMQ2vN"
   },
   "source": [
    "## Placeholders\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/sandeepmj/scrape-example-page/master/images/placeholder2.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zi6fkagQ2vN"
   },
   "source": [
    "## Placeholders\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/sandeepmj/scrape-example-page/master/images/placeholder3.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs5WSXMGQ2vN"
   },
   "source": [
    "## Filling the Placeholder\n",
    "\n",
    "### We use ```.format()``` to fill in values into the ```{}```placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Wk7B2WjiQ2vN"
   },
   "outputs": [],
   "source": [
    "## here's our base url\n",
    "\n",
    "base_url = \"https://www.example{}.html\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PvEyUA0aQ2vN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "## Using a ```for loop```\n",
    "\n",
    "for url_number in range (1,7):\n",
    "    print(url_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.example1.html\n",
      "https://www.example2.html\n",
      "https://www.example3.html\n",
      "https://www.example4.html\n",
      "https://www.example5.html\n",
      "https://www.example6.html\n"
     ]
    }
   ],
   "source": [
    "# Now print the url. Remember that the last number is not inclussive. It only prints 6\n",
    "\n",
    "\n",
    "for url_number in range (1,7):\n",
    "    print(base_url.format(url_number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.example1.html',\n",
       " 'https://www.example2.html',\n",
       " 'https://www.example3.html',\n",
       " 'https://www.example4.html',\n",
       " 'https://www.example5.html',\n",
       " 'https://www.example6.html']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list\n",
    "\n",
    "all_urls = []\n",
    "for url_number in range (1,7):\n",
    "    all_urls.append(base_url.format(url_number))\n",
    "\n",
    "all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KrgrcSVYQ2vO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.example1.html',\n",
       " 'https://www.example2.html',\n",
       " 'https://www.example3.html',\n",
       " 'https://www.example4.html',\n",
       " 'https://www.example5.html',\n",
       " 'https://www.example6.html']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using list comprehension\n",
    "\n",
    "all_urls_lc = [base_url.format (url_number) for url_number in range (1,7)]\n",
    "all_urls_lc\n",
    "                               \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jW-gnRagQ2vO"
   },
   "source": [
    "### 2. Using f-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "e8hJx1nSQ2vO"
   },
   "outputs": [],
   "source": [
    "## base url of site to scrape\n",
    "\n",
    "base_url = \"https:/www.example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https:/www.example1.html\n"
     ]
    }
   ],
   "source": [
    "# Create an f string to add more values to the url\n",
    "\n",
    "print(f\"{base_url}1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JGQMfxyrQ2vO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https:/www.example1\n",
      "https:/www.example2\n",
      "https:/www.example3\n",
      "https:/www.example4\n",
      "https:/www.example5\n",
      "https:/www.example6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using a ```for loop```\n",
    "\n",
    "fs_fl = []\n",
    "for number in range (1,7):\n",
    "    print(f\"{base_url}{number}\")\n",
    "   \n",
    "fs_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https:/www.example1',\n",
       " 'https:/www.example2',\n",
       " 'https:/www.example3',\n",
       " 'https:/www.example4',\n",
       " 'https:/www.example5',\n",
       " 'https:/www.example6']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now store it\n",
    "\n",
    "\n",
    "fs_fl = []\n",
    "for number in range (1,7):\n",
    "    fs_fl.append(f\"{base_url}{number}\")\n",
    "   \n",
    "fs_fl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-WbAbHYLVcfX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https:/www.example1.html',\n",
       " 'https:/www.example2.html',\n",
       " 'https:/www.example3.html',\n",
       " 'https:/www.example4.html',\n",
       " 'https:/www.example5.html',\n",
       " 'https:/www.example6.html']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using list comprehension\n",
    "\n",
    "fs_lc = [ f\"{base_url}{number}.html\" for number in range (1,7) ]\n",
    "fs_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mrJexdPh-JIq"
   },
   "outputs": [],
   "source": [
    "## f string base url\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3lZUHi32-Sp7"
   },
   "outputs": [],
   "source": [
    "## using list comprehension\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_oDySdwQ2vO"
   },
   "source": [
    "## Back to our scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PLsGGNjTQ2vP"
   },
   "outputs": [],
   "source": [
    "## let's remind ourselves of url variable's value\n",
    "\n",
    "url = \"https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page{}.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElvFr3AQQ2vP"
   },
   "source": [
    "## We know we need a placeholder value of upto ```4```\n",
    "## Let's create a variable called  ```total_pages``` to match number of pages on site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "N6Vz-D3LQ2vP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page2.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page3.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page4.html']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## total pages to scrape\n",
    "\n",
    "total_pages = 5 \n",
    "mylinks = [url.format(number) for number in range (1, total_pages)]\n",
    "mylinks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "CcGXP_Nn_juK"
   },
   "outputs": [],
   "source": [
    "## generates urls and loop through to get response from surver (are you getting 200?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51i7AzHFQ2vP"
   },
   "source": [
    "# We have a problem...\n",
    "\n",
    "### We're hitting the server way too fast. We have to add a delay before we proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyDiu5HVQ2vQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's import the required libaries to create a delay\n",
    "from random import randrange ##  allows us to randomize numbers library\n",
    "import time ## time tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code with the delay/Scrape multiple urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html\n",
      "https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page2.html\n",
      "https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page3.html\n",
      "https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page4.html\n"
     ]
    }
   ],
   "source": [
    "# This displays which links I'm going to itterate through\n",
    "for link in mylinks:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 1 of 4\n",
      "snoozing for 11 seconds before next scrape\n",
      "Scraping 2 of 4\n",
      "snoozing for 10 seconds before next scrape\n",
      "Scraping 3 of 4\n",
      "snoozing for 7 seconds before next scrape\n",
      "Scraping 4 of 4\n",
      "snoozing for 8 seconds before next scrape\n",
      "All done....\n"
     ]
    }
   ],
   "source": [
    "# The counter is for....\n",
    "\n",
    "# This is the list that will hold all my df. \n",
    "# Written like this: all_df = [], I will get a big list of dataframes\n",
    "# To wind up with actual dataframe inside the list I need to slice it bellow\n",
    "\n",
    "all_df = [] #this holds all scraped dataframes\n",
    "busted_links = [] # this holds all the broken links \n",
    "\n",
    "counter = 1\n",
    "for link in mylinks:\n",
    "    # This flag with the f string tells me in which part of the process I'm in\n",
    "    # To get the total number of urls in my link, I use {len(mylinks)}\n",
    "    print(f\"Scraping {counter} of {len(mylinks)}\")\n",
    "    # I need to add one to the counter, WHY?. What command is this giving to the counter?\n",
    "    # It increments the url inside the list by one. CONFIRM THIS. \n",
    "    counter += 1\n",
    "    # The values that I need to get are in each individual \"link\". \n",
    "    # NOT THE WHOLE LIST \"mylinks\", but the individual value \"link\"\n",
    "    response = requests.get(link)\n",
    "    # NOW, IT'S TIME TO PREPARE FOR AN ERROR\n",
    "    # I put the number 200 because that's when the website is working. The 2 == are checking instead\n",
    "    # of assigning the value\n",
    "    # So, if you get the word 200, then...\n",
    "    # This is to avoid my whole code from stopping if a mistake happens\n",
    "    # I'm saying: only if this goes through, you can do the next step\n",
    "    if response.status_code == 200:\n",
    "        df = pd.read_html(response.text)\n",
    "    # I have my df, I need to store it somewhere.\n",
    "    # I'm appending it to some kind of lists, which means that I need to create a list that \n",
    "    # will hold them. \n",
    "    # The slice creates a list with individual dataframes in it, instead of nested lists\n",
    "        all_df.append(df[0])\n",
    "    # Now lets solve \"if there's a broken link issue\"\n",
    "    # This is to know how much data I'm mission out of my hundreds of links\n",
    "    else: \n",
    "        print(f\"{link} returned a busted link with {response.code_status}\")\n",
    "    # Let's hold on to the link that broke. Like df, busted links it's a list I oppened above \n",
    "        busted_links.append(link)\n",
    "    # Now I need to slow it down. Do it outside the statement \n",
    "    \n",
    "# It will pick a number between 5 and 12.\n",
    "# I put it here because I want the for loop to do it's job before it snoozes\n",
    "    snoozer = randrange(5,12)\n",
    "    print(f\"snoozing for {snoozer} seconds before next scrape\")\n",
    "    # What does this do?\n",
    "    time.sleep(snoozer)\n",
    "    \n",
    "# After it's done running through all of my links, I need to print \"All done\".\n",
    "# I do this at the same level of the for loop\n",
    "\n",
    "print(\"All done....\")\n",
    "    \n",
    "        \n",
    "         \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                 Animal  Weight(kg)    Type\n",
       " 0            Blue whale      136000  Marine\n",
       " 1         Bowhead whale      100000  Marine\n",
       " 2             Fin whale       70000  Marine\n",
       " 3  Southern right whale       45000  Marine\n",
       " 4        Humpback whale       30000  Marine,\n",
       "                  Animal  Weight(kg)    Type\n",
       " 0            Gray whale       28500  Marine\n",
       " 1  Northern right whale       23000  Marine\n",
       " 2             Sei whale       20000  Marine\n",
       " 3         Bryde's whale       16000  Marine\n",
       " 4  Baird's beaked whale       11380  Marine,\n",
       "                       Animal  Weight(kg)         Type\n",
       " 0                Minke whale        7500       Marine\n",
       " 1  Northern bottlenose whale        6500       Marine\n",
       " 2     Gervais's beaked whale        5600       Marine\n",
       " 3           African elephant        4800  Terrestrial\n",
       " 4               Killer whale        3988       Marine,\n",
       "                      Animal  Weight(kg)         Type\n",
       " 0              Hippopotamus        3750  Terrestrial\n",
       " 1            Asian elephant        3178  Terrestrial\n",
       " 2     Cuvier's beaked whale        2701       Marine\n",
       " 3  Short-finned pilot whale        2200       Marine\n",
       " 4          White rhinoceros        2175  Terrestrial]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the list\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It returns nothing because there were no busted links\n",
    "busted_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOnd8mhPDUR0"
   },
   "outputs": [],
   "source": [
    "## let's remind ourselves of url variable's value\n",
    "\n",
    "base_url = \"https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKhoz13wDEKu"
   },
   "outputs": [],
   "source": [
    "## ## for loop with timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uPWDrxJQ2vQ"
   },
   "source": [
    "## Working Around Errors\n",
    "\n",
    "When you scrape hundreds of pages, there's chance that one of the URLs might be a dud.\n",
    "\n",
    "We can set up a error control to see what kind of responses we get:\n",
    "\n",
    "```<Response [200]>``` means website is accessible.\n",
    "\n",
    "```<Response [404]>``` means broken link or no page on content.\n",
    "\n",
    "In that case, your whole code might break and you'll have to figure out where it broke.\n",
    "\n",
    "We can make that easier with conditional logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFcihmt6Q2vQ"
   },
   "outputs": [],
   "source": [
    "## CHECK FOR ERRORs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOlkUp23h2wF"
   },
   "outputs": [],
   "source": [
    "## show broken links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gyRplcgQ2vQ"
   },
   "source": [
    "# All in One Step\n",
    "\n",
    "Because we are using a  ```for loop``` that cycles through each link to do multiple steps on our target data, we need to have it done as one step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJoLS9AgQ2vR"
   },
   "outputs": [],
   "source": [
    "## Combined url timed nav with table scrape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-lESTDPMP8s"
   },
   "source": [
    "### What does this list hold?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all the dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Weight(kg)</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue whale</td>\n",
       "      <td>136000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bowhead whale</td>\n",
       "      <td>100000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fin whale</td>\n",
       "      <td>70000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Southern right whale</td>\n",
       "      <td>45000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Humpback whale</td>\n",
       "      <td>30000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gray whale</td>\n",
       "      <td>28500</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Northern right whale</td>\n",
       "      <td>23000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sei whale</td>\n",
       "      <td>20000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bryde's whale</td>\n",
       "      <td>16000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baird's beaked whale</td>\n",
       "      <td>11380</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Minke whale</td>\n",
       "      <td>7500</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Northern bottlenose whale</td>\n",
       "      <td>6500</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gervais's beaked whale</td>\n",
       "      <td>5600</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>African elephant</td>\n",
       "      <td>4800</td>\n",
       "      <td>Terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Killer whale</td>\n",
       "      <td>3988</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hippopotamus</td>\n",
       "      <td>3750</td>\n",
       "      <td>Terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Asian elephant</td>\n",
       "      <td>3178</td>\n",
       "      <td>Terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cuvier's beaked whale</td>\n",
       "      <td>2701</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Short-finned pilot whale</td>\n",
       "      <td>2200</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>White rhinoceros</td>\n",
       "      <td>2175</td>\n",
       "      <td>Terrestrial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Animal  Weight(kg)         Type\n",
       "0                  Blue whale      136000       Marine\n",
       "1               Bowhead whale      100000       Marine\n",
       "2                   Fin whale       70000       Marine\n",
       "3        Southern right whale       45000       Marine\n",
       "4              Humpback whale       30000       Marine\n",
       "5                  Gray whale       28500       Marine\n",
       "6        Northern right whale       23000       Marine\n",
       "7                   Sei whale       20000       Marine\n",
       "8               Bryde's whale       16000       Marine\n",
       "9        Baird's beaked whale       11380       Marine\n",
       "10                Minke whale        7500       Marine\n",
       "11  Northern bottlenose whale        6500       Marine\n",
       "12     Gervais's beaked whale        5600       Marine\n",
       "13           African elephant        4800  Terrestrial\n",
       "14               Killer whale        3988       Marine\n",
       "15               Hippopotamus        3750  Terrestrial\n",
       "16             Asian elephant        3178  Terrestrial\n",
       "17      Cuvier's beaked whale        2701       Marine\n",
       "18   Short-finned pilot whale        2200       Marine\n",
       "19           White rhinoceros        2175  Terrestrial"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## concat here. To put all of these together\n",
    "# concat asks for the list of dataframes I'm trying to concat\n",
    "# because all of that dataframes have a defult numbers, I need to reset that: ignore\n",
    "\n",
    "df = pd.concat(all_df, ignore_index = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to csv\n",
    "\n",
    "# 1:42:02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's revisit this in a momment and convert these last couple of steps into a ```function```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lists(list_name, filename):\n",
    "    df = pd.concat(list_name, ignore_index = True)\n",
    "    df.to_csv(filename, encoding = \"UTF-8\", index = False)\n",
    "    print(f\"{filename} should be in your current folder\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1259123126.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/51/zfcz7v952f74skxnnh3c0g8m0000gn/T/ipykernel_5082/1259123126.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_amnimals = def process_lists(all_df, \"big_animals.csv\")\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_amnimals = def process_lists(all_df, \"big_animals.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "week-6-multi-page-table scrape_BLANK.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
